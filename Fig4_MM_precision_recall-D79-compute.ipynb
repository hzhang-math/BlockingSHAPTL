{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, we plot the precision and recall for duration 7 and duration 9 case for MMmodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2024-04-02 09:12:52.420267: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-02 09:13:03.040850: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-02 09:13:03.040877: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-02 09:13:03.045684: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-02 09:13:08.523396: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 09:13:13.006478: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/hz1994/blocking/data_MMmodel/reduceddim/\n",
      "/scratch/hz1994/blocking/data_MMmodel/TMindex/\n",
      "/scratch/hz1994/blocking/data_MMmodel/dim/\n",
      "/scratch/hz1994/blocking/data_MMmodel/conditionT/\n",
      "/scratch/hz1994/blocking/data_MMmodel/CNNmodels/\n",
      "/scratch/hz1994/blocking/data_MMmodel/fig_MMmodel/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "\n",
    "import cartopy\n",
    "from cartopy import crs as ccrs\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from os.path import join, exists\n",
    "from os import mkdir\n",
    "import scipy\n",
    "import netCDF4\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.ticker import (LongitudeFormatter, LatitudeFormatter,\n",
    "                                LatitudeLocator, LongitudeLocator)\n",
    "import pandas as pd\n",
    "import matplotlib.path as mpath\n",
    "from matplotlib.colors import TwoSlopeNorm \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.fft import fft, ifft\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import importlib.util\n",
    "import pathlib\n",
    "import MM_util_AI\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_score\n",
    "spec = importlib.util.spec_from_file_location(\"MM_dataprepare\", \\\n",
    "                        \"/scratch/hz1994/blocking/MMmodel/MMmodel/notebooks/All_paper_Jupyter_script/MM_dataprepare.py\")\n",
    "MM_dataprepare = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"module.name\"] = MM_dataprepare\n",
    "spec.loader.exec_module(MM_dataprepare)\n",
    "spec = importlib.util.spec_from_file_location(\"MM_utilblocking\", \\\n",
    "                        \"/scratch/hz1994/blocking/MMmodel/MMmodel/notebooks/All_paper_Jupyter_script/MM_utilblocking.py\")\n",
    "MM_utilblocking = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"module.name\"] = MM_utilblocking\n",
    "spec.loader.exec_module(MM_utilblocking)\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_score\n",
    "with open(\"/scratch/hz1994/blocking/data_MMmodel/filepath.txt\",\"r\") as fi:\n",
    "    for ln in fi:\n",
    "        if ln.startswith(\"Reduced_dim_variables\"):\n",
    "            rd_path=ln.strip().split('\\t')[1]\n",
    "        if ln.startswith(\"TMindex_filepath\"):\n",
    "            TMindex_path=ln.strip().split('\\t')[1]   \n",
    "        if ln.startswith(\"dimensionalized_filepath\"):\n",
    "            dim_path=ln.strip().split('\\t')[1]   \n",
    "        if ln.startswith(\"nondimensionalized_filepath\"):\n",
    "            nondim_path=ln.strip().split('\\t')[1]\n",
    "        if ln.startswith(\"conditionedT_filepath\" ):\n",
    "            train_path=ln.strip().split('\\t')[1]\n",
    "        if ln.startswith(\"model_filepath\" ):\n",
    "            models_path=ln.strip().split('\\t')[1]\n",
    "        if ln.startswith(\"fig_filepath\" ):\n",
    "            fig_path=ln.strip().split('\\t')[1]            \n",
    "            \n",
    "print(rd_path)\n",
    "print(TMindex_path)\n",
    "print(dim_path)\n",
    "print(train_path)\n",
    "print(models_path)\n",
    "print(fig_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "T=1\n",
    "EPOCH=30\n",
    "name=\"1250k_lowpass3dys\"\n",
    "epsilon=0\n",
    "choleskyL=np.load('/scratch/hz1994/blocking/data_MMmodel/conditionT/T/cholesky_L.npy') \n",
    "setA=\"T\"\n",
    "train_path_setA=train_path+setA+\"/\"\n",
    "models_path_setA=models_path+setA+\"/\"\n",
    " \n",
    "Duration=7\n",
    "if Duration==5:\n",
    "    test_data=np.load(\"/scratch/hz1994/blocking/data_MMmodel/conditionT/T/data_X_T1_1250k_lowpass3dys_proc_test/test_data.npy\")\n",
    "    test_labels=np.load(\"/scratch/hz1994/blocking/data_MMmodel/conditionT/T/data_X_T1_1250k_lowpass3dys_proc_test/test_labels.npy\")\n",
    "if Duration==7:\n",
    "    test_data=np.load(\"/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_7d/T/test_data.npy\")\n",
    "    test_labels=np.load(\"/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_7d/T/test_labels.npy\")\n",
    "if Duration==9:\n",
    "    test_data=np.load(\"/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_9d/T/test_data.npy\")\n",
    "    test_labels=np.load(\"/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_9d/T/test_labels.npy\")\n",
    "\n",
    "print(Duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute=False\n",
    "if recompute:\n",
    "    \n",
    "    data_amount_list=['10.0k','100.0k','1000.0k']\n",
    "    random_seed_list=np.arange(30,40)\n",
    "    # cnnsize_list=[\"normal\", \"smaller\",\"smaller_smaller\"]\n",
    "    cnnsize_list=[\"normal\"]\n",
    "    pre_subname=\"/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_%dd/models_T_1_committor_1250k_lowpass3dys/\"\\\n",
    "        %Duration \n",
    "    lines1=[]\n",
    "    lines2=[]\n",
    "    for d, data_amount in enumerate(data_amount_list):\n",
    "        for c, cnnsize in enumerate(cnnsize_list):\n",
    "            precision=[]\n",
    "            recall=[]\n",
    "            for random_seed in random_seed_list:\n",
    "                subname=\"/batches_resampling_\"+\"data_\"+data_amount+\"_\"+cnnsize+\"_cnn_\"+\\\n",
    "                    \"regularize\"+\"_%.3e\"%epsilon+\"_rs_%d/\"%random_seed\n",
    "                path = pre_subname+subname\n",
    "    \n",
    "                tn_list=[]\n",
    "                fp_list=[]\n",
    "                fn_list=[]\n",
    "                tp_list=[]\n",
    "                for epoch in range(31):\n",
    "                    weightpath=path+\"cp-%04d.ckpt\"%epoch\n",
    "                    model = MM_util_AI.make_model((18,90,3))\n",
    "                    model.load_weights(weightpath).expect_partial()\n",
    "                    y_pred = model.predict(test_data)\n",
    "                    y_pred = np.argmax(y_pred, axis=1)\n",
    "                    tn, fp, fn, tp = confusion_matrix(test_labels[:,1], y_pred).ravel()\n",
    "                    tn_list.append(tn)\n",
    "                    fp_list.append(fp)\n",
    "                    fn_list.append(fn)\n",
    "                    tp_list.append(tp)\n",
    "                np.save(path+\"TN.npy\",tn_list)\n",
    "                np.save(path+\"FP.npy\",fp_list)\n",
    "                np.save(path+\"FN.npy\",fn_list)\n",
    "                np.save(path+\"TP.npy\",tp_list)\n",
    "    \n",
    "    lines1=[]\n",
    "    lines2=[]\n",
    "    for d, data_amount in enumerate(data_amount_list):\n",
    "        for c, cnnsize in enumerate(cnnsize_list):\n",
    "            for random_seed in random_seed_list:\n",
    "                subname=\"/batches_resampling_\"+\"data_\"+data_amount+\"_\"+cnnsize+\"_cnn_\"+\\\n",
    "                    \"regularize\"+\"_%.3e\"%epsilon+\"_rs_%d/\"%random_seed\n",
    "                path = pre_subname+subname\n",
    "                tn_list=np.load(path+\"TN.npy\")\n",
    "                fp_list=np.load(path+\"FP.npy\")\n",
    "                fn_list=np.load(path+\"FN.npy\")\n",
    "                tp_list=np.load(path+\"TP.npy\")\n",
    "                recall=tp_list/(tp_list+fn_list) \n",
    "                precision=tp_list/(tp_list+fp_list)\n",
    "    \n",
    "                np.save(path+\"precision.npy\", precision)    \n",
    "                np.save(path+\"recall.npy\", recall)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_7d/models_T_1_committor_1250k_lowpass3dys//Fig5_plot_precision_10.0k.npy\n",
      "/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_7d/models_T_1_committor_1250k_lowpass3dys//Fig5_plot_precision_100.0k.npy\n",
      "/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_7d/models_T_1_committor_1250k_lowpass3dys//Fig5_plot_precision_1000.0k.npy\n",
      "/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_9d/models_T_1_committor_1250k_lowpass3dys//Fig5_plot_precision_10.0k.npy\n",
      "/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_9d/models_T_1_committor_1250k_lowpass3dys//Fig5_plot_precision_100.0k.npy\n",
      "/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_9d/models_T_1_committor_1250k_lowpass3dys//Fig5_plot_precision_1000.0k.npy\n"
     ]
    }
   ],
   "source": [
    "#The data are all in /scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_7d/models_T_1_committor_1250k_lowpass3dys/\"+\\\n",
    "#  \"batches_resampling_data_%s_normal_cnn_regularize_0.000e+00_rs_%d/, and if recompute==True we will connect those together\n",
    "# as the input of plotting Fig5.\n",
    "data_amount_list=['10.0k','100.0k','1000.0k']\n",
    "random_seed_list=np.arange(30,40)\n",
    "recompute=True\n",
    "if recompute==True:\n",
    "    for Duration in [7,9]:\n",
    "        pre_subname=\"/scratch/hz1994/blocking/data_MMmodel/conditionT/Duration_%dd/models_T_1\"%Duration+\\\n",
    "                \"_committor_1250k_lowpass3dys/\" \n",
    "        for d, data_amount in enumerate(data_amount_list):\n",
    "            precision=[]\n",
    "            recall=[]\n",
    "            for random_seed in random_seed_list:\n",
    "                subname=\"/batches_resampling_\"+\"data_\"+data_amount+\"_\"+\"normal\"+\"_cnn_\"+\\\n",
    "                    \"regularize\"+\"_%.3e\"%epsilon+\"_rs_%d/\"%random_seed\n",
    "                path = pre_subname+subname\n",
    "                precision.append(np.load(path+\"precision.npy\")[1:])\n",
    "                recall.append(np.load(path+\"recall.npy\")[1:]) \n",
    "            print(pre_subname+\"/Fig5_plot_precision_%s.npy\"%data_amount) \n",
    "            np.save(pre_subname+\"/Fig5_plot_precision_%s.npy\"%data_amount,precision )\n",
    "            np.save(pre_subname+\"/Fig5_plot_recall_%s.npy\"%data_amount,recall )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
